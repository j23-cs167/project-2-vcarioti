{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j23-cs167/project-2-vcarioti/blob/main/Project2_Carioti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIepkBIuT_Pl"
      },
      "source": [
        "# Project #2\n",
        "##Name: Vince Carioti\n",
        "\n",
        "Proposed Points (out of 25):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbwKLNhzP8YO"
      },
      "source": [
        "# 1. Problem\n",
        "State the problem you are trying to solve with this machine learning experiment. Include a description of the data, where you got the data, and what you're trying to predict.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwseoUsMmCz2"
      },
      "source": [
        "I am trying to solve the problem of discovering how well a Convolutional Neural Network can classify Pictures of the following unique class settings: {Buildings, Forests, Glaciers, Mountains, Seas, Streets}. The data set I am using is comprised of image data (14000 training, 3000 testing) including the above listed natural scenes, and was found on Kaggle under the name 'Intel Image Classification.' The goal of this experiment is to correctly classify as many of the natural scenes in each of these images as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR_foVOeQVL7"
      },
      "source": [
        "# 2. Data Preparation\n",
        "Explain your data preparation. What did you have to do to get your data in shape for your experiments? Why are you certain that you data is clean and prepared for use in your algorithms?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMDJDnW_mOWu"
      },
      "source": [
        "Data preparation for this experiment was relatively simple. I started by importing all keras packages and connecting to Google Drive. I then defined the image dimensions and batch size, specified paths for training and testing data, and rescaled my pixel values to 0 to 1 from 0 to 255. Finally, I defined my training and testing data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dUdBChRmKxR",
        "outputId": "07d25bb3-db8b-4717-addb-fd2e4cabf8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 14039 images belonging to 6 classes.\n",
            "Found 3000 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# load and prepare your data here\n",
        "import keras\n",
        "import tensorflow \n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys\n",
        "\n",
        "## Connect to Drive\n",
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## Image dimensions\n",
        "img_width = 150\n",
        "img_height = 150\n",
        "\n",
        "## Directories for testing and training data\n",
        "train_data_dir = '/content/drive/MyDrive/Datasets/project2/seg_train/seg_train' \n",
        "test_data_dir = '/content/drive/MyDrive/Datasets/project2/seg_test/seg_test'\n",
        "\n",
        "## To feed the training images to the neural network in batches of 32 images \n",
        "batch_size = 64\n",
        "\n",
        "## Rescale pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "## Look for training and testing data and classifying based on subfolder\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc7HMmNPR10W"
      },
      "source": [
        "# 3. Research\n",
        "\n",
        "Put your code and your experiments here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfaACsEOR4U5",
        "outputId": "d2b45f27-4b4b-4ef9-a698-b038be1777d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 41472)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1327136   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,337,313\n",
            "Trainable params: 1,337,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# code goes here... don't forget to include graphs. Professor Urness loves graphs.\n",
        "# Building my CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) #flatten the convolutional layer so it can go into a fully-connected layer\n",
        "model.add(Dense(32)) #fully-connected layer\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2A2Vy7SLKt",
        "outputId": "ee5bb893-2523-46a0-da43-883645641b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "220/220 [==============================] - 3920s 18s/step - loss: nan - accuracy: 0.1566 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 2/10\n",
            "220/220 [==============================] - 37s 169ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 3/10\n",
            "220/220 [==============================] - 39s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 4/10\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 5/10\n",
            "220/220 [==============================] - 38s 173ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 6/10\n",
            "220/220 [==============================] - 38s 172ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 7/10\n",
            "220/220 [==============================] - 37s 169ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 8/10\n",
            "220/220 [==============================] - 38s 173ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 9/10\n",
            "220/220 [==============================] - 38s 172ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 10/10\n",
            "220/220 [==============================] - 39s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n"
          ]
        }
      ],
      "source": [
        "#training and testing the first model \n",
        "training_results = model.fit(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=10, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtracted a conv and pool layer as well as adjusted batch size above. \n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten()) #flatten the convolutional layer so it can go into a fully-connected layer\n",
        "model2.add(Dense(64)) #fully-connected layer\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "opt2 = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVHqhdvMadpd",
        "outputId": "62b7dd46-38b0-448e-c850-0efd777f2db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 175232)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,215,873\n",
            "Trainable params: 11,215,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing 2nd model\n",
        "training_results2 = model2.fit(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=20, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z8kT5OidzCR",
        "outputId": "41d538f7-4f79-4328-863b-283077f8de86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "220/220 [==============================] - 40s 183ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 2/20\n",
            "220/220 [==============================] - 40s 180ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 3/20\n",
            "220/220 [==============================] - 38s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 4/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 5/20\n",
            "220/220 [==============================] - 38s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 6/20\n",
            "220/220 [==============================] - 41s 184ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 7/20\n",
            "220/220 [==============================] - 39s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 8/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 9/20\n",
            "220/220 [==============================] - 39s 177ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 10/20\n",
            "220/220 [==============================] - 38s 173ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 11/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 12/20\n",
            "220/220 [==============================] - 38s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 13/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 14/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 15/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 16/20\n",
            "220/220 [==============================] - 39s 177ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 17/20\n",
            "220/220 [==============================] - 39s 176ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 18/20\n",
            "220/220 [==============================] - 38s 174ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 19/20\n",
            "220/220 [==============================] - 38s 175ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n",
            "Epoch 20/20\n",
            "220/220 [==============================] - 40s 180ms/step - loss: nan - accuracy: 0.1564 - val_loss: nan - val_accuracy: 0.1457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(training_results.history['accuracy'])\n",
        "plt.plot(training_results.history['val_accuracy'])\n",
        "plt.title(' Default model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "ltnD5DJxMeWz",
        "outputId": "6697f196-7dbd-46de-94f0-e661747f8aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-230b2c4caf34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Default model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This Graph is representative of both models, as the training and testing accuracy did not change from the first epoch\n",
        "#Sososososo frustrating\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(training_results2.history['accuracy'])\n",
        "plt.plot(training_results2.history['val_accuracy'])\n",
        "plt.title(' CNN with 20 epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "TyiCns-yux4E",
        "outputId": "af2a88a1-1e5a-48f4-9a1a-4b67b13999ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Analysis\n",
        "What did you discover? What insights/recommendations do you have? What did you find that was interesting? Which model was your best model, which models didn't work well? Why do you think this is? In general, I want a discussion of your experiment, the results, and what they mean."
      ],
      "metadata": {
        "id": "UPkjkHvQOQzO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k17sKBZUmqIH"
      },
      "source": [
        "From these experiments, I've discovered that using this specific model of convolutional neural network on this dataset is not accurate at classifying images. After running a multitude of CNN's and changing different variables such as batch size, number of epochs, which optimizer was used, and what type of loss metric was used, my accuracy of the CNN did not change. I found it interesting that my models were less than 20% accurate, and what I found more interesting was the fact that the accuracy never changed from 15%. I'm really not sure what caused this to happen even after I changed the structure and variables of the model. \n",
        "\n",
        "As far as recommendations I have, I would recommend either a different classification model (if available) or to follow the way that the creator of the Kaggle dataset loaded their data and created their model. Rather than splitting up the training and testing data with a datagen function to resize the pixels, the creator of the dataset made a different type of function and added two more variables: test_predictions and train_predictions. He was able to use these arrays with labels to classify the images and make a model that was monumentally more accurate at identifying which type of image was which. \n",
        "\n",
        "To summarize my results, I will state that with these created convolutional neural networks and this dataset, it's highly difficult to get even 16% accurate, making it hardly a viable model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TemAuKxlm6dQ"
      },
      "source": [
        "# 5. Bumps in the Road\n",
        "What challenges did you encounter? How did you overcome these challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXEVEG9FnHgQ"
      },
      "source": [
        "I actually encountered a multitude of problems while working on this project. The first problem started when my first model finished epoch 1/20 then froze for an hour. I refreshed the page and ran it again and the same thing happened, so I made a new model with less epochs and the same optimizer and loss metric that the creator of the kaggle dataset used. When nothing changed with that model, I decided to add a convolutional layer and a pooling layer, which made it take slightly longer and had the same result. Finally, I tried the exact same simple model setup that seemed to get the kaggle creator upwards of 90% accuracy, which had less layers in all, and it was still the exact same. \n",
        "\n",
        "I really don't know if I just messed something up so incredibly bad and that's why model is inaccurate, but I really struggled with tweaking a lot of different things on this and still got the exact same results every time over the course of days. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}